{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8113344e",
   "metadata": {},
   "source": [
    "# Prophet Recursive model\n",
    "Overall process:\n",
    "- Iteratively run Prophet model on 100 unique store chains\n",
    "- Analyse data preprocessing, MAPE, SMAPE and Prophet prediction time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b62a25-6a26-47bb-9b74-fa2b0800dffb",
   "metadata": {
    "collapsed": false,
    "name": "cell2",
    "resultHeight": 227
   },
   "source": [
    "### 1. Create table to store Prophet model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e551b-48bb-4b05-8582-7f2f8fc6b6ce",
   "metadata": {
    "language": "sql",
    "name": "cell1",
    "resultHeight": 112
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE prophet_model_performance\n",
    "(\n",
    "    store_chain_id NUMBER(38,0),\n",
    "    mape FLOAT,\n",
    "    smape FLOAT,\n",
    "    prophet_elapsed_time FLOAT,\n",
    "    data_preprocessing_time FLOAT,\n",
    "    overall_time FLOAT\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575cc807-4264-46b0-87ba-2421177baf7f",
   "metadata": {
    "collapsed": false,
    "name": "cell3",
    "resultHeight": 148
   },
   "source": [
    "### 2. Create stored procedure for data preprocessing\n",
    "- Extract transactions for the specified store chain id\n",
    "- Aggregate total sales per day\n",
    "- Impute any missing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db6c09-ed06-4e1b-a534-065944dfeba3",
   "metadata": {
    "language": "sql",
    "name": "cell4",
    "resultHeight": 112
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE PROCEDURE data_preprocessing_procedure(store_id INT)\n",
    "RETURNS STRING\n",
    "LANGUAGE SQL\n",
    "AS\n",
    "$$\n",
    "    BEGIN\n",
    "    -- Extract daily sales dataset for specified store_id\n",
    "    CREATE OR REPLACE TABLE prophet_preprocessed_transactions AS\n",
    "    WITH store_preprocessed_transactions AS(\n",
    "        SELECT store_chain_id, purchase_amount, date, offer_date FROM preprocessed_transactions\n",
    "        WHERE store_chain_id=:store_id\n",
    "    ),\n",
    "    prophet_dataset AS(\n",
    "        WITH filtered_transactions AS (\n",
    "            SELECT \n",
    "                store_chain_id,\n",
    "                date,\n",
    "                purchase_amount, \n",
    "                offer_date\n",
    "            FROM store_preprocessed_transactions\n",
    "            WHERE \n",
    "                (SELECT COUNT(offer_date) FROM store_preprocessed_transactions) = 0 OR\n",
    "                date < (SELECT MIN(offer_date) FROM store_preprocessed_transactions)\n",
    "        )\n",
    "        SELECT \n",
    "            store_chain_id,\n",
    "            date,\n",
    "            SUM(purchase_amount) AS total_sales,\n",
    "        FROM filtered_transactions\n",
    "        GROUP BY store_chain_id, date\n",
    "        ORDER BY store_chain_id, date\n",
    "    ),\n",
    "    date_range AS(\n",
    "        SELECT \n",
    "            MIN(date) AS min_date,\n",
    "            MAX(date) AS max_date,\n",
    "        FROM prophet_dataset\n",
    "    ),\n",
    "    \n",
    "    -- Create date table\n",
    "    date_table AS (\n",
    "        SELECT \n",
    "            min_date AS date,\n",
    "            max_date \n",
    "        FROM date_range\n",
    "        UNION ALL\n",
    "        SELECT\n",
    "            DATEADD(day, 1, date),\n",
    "            max_date\n",
    "        FROM date_table\n",
    "        WHERE date_table.date < date_table.max_date\n",
    "    )\n",
    "    \n",
    "    -- Left join with transactions table\n",
    "    SELECT \n",
    "        dt.date,\n",
    "        COALESCE(s.total_sales, 0) AS total_sales,\n",
    "    FROM date_table dt\n",
    "    LEFT JOIN prophet_dataset s\n",
    "        ON dt.date = s.date\n",
    "    ORDER BY s.date;\n",
    "    RETURN 'SUCCESS';\n",
    "    END\n",
    "$$;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db83e9-e6f4-4ff2-a311-b36790fbbb35",
   "metadata": {
    "collapsed": false,
    "name": "cell6",
    "resultHeight": 91
   },
   "source": [
    "### 3. Create stored procedure for Prophet model\n",
    "- Call upon data preprocessing stored procedure before fitting the Prophet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e31fe-f922-4578-9355-8bea8a5ba961",
   "metadata": {
    "language": "sql",
    "name": "cell5",
    "resultHeight": 112,
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE PROCEDURE run_prophet_forecasting(store_id INT)\n",
    "RETURNS STRING\n",
    "LANGUAGE PYTHON \n",
    "RUNTIME_VERSION = '3.9'\n",
    "HANDLER = 'prophet_main'\n",
    "PACKAGES = (\n",
    "    'snowflake-snowpark-python',\n",
    "    'pandas',\n",
    "    'prophet',\n",
    "    'scikit-learn',\n",
    "    'numpy'\n",
    ")\n",
    "AS\n",
    "$$\n",
    "def prophet_main(session, store_id):\n",
    "\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from prophet import Prophet\n",
    "    from sklearn.metrics import mean_absolute_percentage_error as MAPE_metrics\n",
    "\n",
    "    TEST_SIZE = 14\n",
    "    TRAIN_SIZE = TEST_SIZE * 4\n",
    "\n",
    "    overall_start_time = time.time()\n",
    "    \n",
    "    # Call data preprocessing stored procedure\n",
    "    preprocessing_start_time = time.time()\n",
    "    session.sql(f\"CALL data_preprocessing_procedure({store_id});\").collect()\n",
    "    session.sql(\"SELECT COUNT(*) FROM prophet_preprocessed_transactions;\").collect()\n",
    "    preprocessing_end_time = time.time()\n",
    "    \n",
    "    \n",
    "    # Read preprocessed dataset\n",
    "    transactions_df = session.table(\"prophet_preprocessed_transactions\")\n",
    "    transactions_df = transactions_df.to_pandas()\n",
    "    transactions_df = transactions_df[[\"DATE\", \"TOTAL_SALES\"]]\n",
    "    transactions_df[\"DATE\"] = pd.to_datetime(transactions_df[\"DATE\"])\n",
    "    transactions_df = transactions_df.sort_values(by='DATE', ignore_index=True)\n",
    "\n",
    "\n",
    "    # Rename columns and split train test set\n",
    "    transactions_df = transactions_df.rename(columns={\"DATE\": \"ds\"})\n",
    "    transactions_df = transactions_df.rename(columns={\"TOTAL_SALES\": \"y\"})\n",
    "    \n",
    "    transactions_df[\"y\"] = transactions_df[\"y\"] + 1\n",
    "    \n",
    "    FLOOR = 0\n",
    "    CAP = transactions_df[\"y\"].max()\n",
    "    \n",
    "    transactions_df[\"floor\"] = 0\n",
    "    transactions_df[\"cap\"] = CAP\n",
    "    \n",
    "    # Split train test set\n",
    "    test_set = transactions_df.iloc[-TEST_SIZE:]\n",
    "    transactions_df = transactions_df.iloc[:-TEST_SIZE]\n",
    "    \n",
    "    # Fit model\n",
    "    train_data = transactions_df[-TRAIN_SIZE:]\n",
    "\n",
    "    prophet_start_time = time.time()\n",
    "    model = Prophet(\n",
    "        seasonality_mode=\"multiplicative\",\n",
    "        growth=\"logistic\"\n",
    "    )\n",
    "    model.fit(train_data)\n",
    "    prophet_end_time = time.time()\n",
    "\n",
    "    df_future = model.make_future_dataframe(periods=TEST_SIZE, freq=\"D\")\n",
    "    df_future[\"floor\"] = FLOOR\n",
    "    df_future[\"cap\"] = CAP\n",
    "    prophet_predictions = model.predict(df_future)\n",
    "    \n",
    "    predictions = prophet_predictions[\"yhat\"].iloc[-TEST_SIZE:].values\n",
    "    val_data = transactions_df[\"y\"].iloc[-TEST_SIZE:]\n",
    "\n",
    "    # Store results\n",
    "    mape = float(MAPE_metrics(test_set[\"y\"], predictions))\n",
    "    smape = float(100/len(test_set[\"y\"]) * np.sum(2 * np.abs(predictions - test_set[\"y\"]) / (np.abs(test_set[\"y\"]) + np.abs(predictions))))\n",
    "\n",
    "    overall_end_time = time.time()\n",
    "    \n",
    "    prophet_time = float(prophet_end_time - prophet_start_time)\n",
    "    preprocessing_time = float(preprocessing_end_time - preprocessing_start_time)\n",
    "    overall_time = float(overall_end_time - overall_start_time)\n",
    "\n",
    "    session.sql(f\"DELETE FROM prophet_model_performance WHERE store_chain_id = {store_id}\").collect()\n",
    "    session.sql(f\"INSERT INTO prophet_model_performance (store_chain_id, mape, smape, prophet_elapsed_time, data_preprocessing_time, overall_time) VALUES ({store_id}, {mape}, {smape}, {prophet_time}, {preprocessing_time}, {overall_time})\").collect()\n",
    "    \n",
    "    return \"SUCCESS\"\n",
    "$$;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b12b530-a6c4-48c5-ba23-14cc53035fdf",
   "metadata": {
    "collapsed": false,
    "name": "cell10",
    "resultHeight": 46
   },
   "source": [
    "### 4. Get 100 unique store id and run prophet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b172b3c-ad14-4288-8d4d-04550403c75b",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "resultHeight": 4703
   },
   "outputs": [],
   "source": [
    "session = get_active_session()\n",
    "session.use_database(\"ml\")\n",
    "session.use_schema(\"retail_store\")\n",
    "\n",
    "df = session.table(\"transactions\")\n",
    "store_chain_list = session.sql(\"SELECT DISTINCT store_chain_id FROM transactions;\")\n",
    "store_chain_list = store_chain_list.to_pandas()\n",
    "store_chain_list = store_chain_list[\"STORE_CHAIN_ID\"].to_list()\n",
    "store_chain_list.sort()\n",
    "\n",
    "# Run default Prophet model on 100 unique store chain daily sales data\n",
    "store_index = 0\n",
    "for i in range(100):\n",
    "    print(f\"Step {i+1}/100: store #{store_chain_list[store_index]}\")\n",
    "    try:\n",
    "        session.sql(f\"CALL run_prophet_forecasting ({store_chain_list[store_index]})\").collect()\n",
    "        print(\"Success\")\n",
    "    except Exception as e:\n",
    "        i -= 1\n",
    "        print(f\"ERROR (Store chain {store_chain_list[store_index]}): {e}\")\n",
    "\n",
    "    store_index += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569e138-0be8-4bbf-b3b7-9c38732f9ff1",
   "metadata": {
    "collapsed": false,
    "name": "cell13",
    "resultHeight": 46
   },
   "source": [
    "### 5. Average performance\n",
    "\n",
    "- Average MAPE: 1.819\n",
    "- Average SMAPE: 26.215\n",
    "- Average Prophet prediction time: 0.197s\n",
    "- Average Preprocessing time: 2.471s\n",
    "- Average Overall time: 3.116s\n",
    "\n",
    "Time analysis: Overall time is slighty higher than Prophet + Preprocessing time, as this does not include SQL DML commands such as deleting and inserting rows into performance table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b7d90-f2d6-454c-b05d-6da11c67c9fe",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "cell8",
    "resultHeight": 439
   },
   "outputs": [],
   "source": [
    "SELECT * FROM prophet_model_performance;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347ccf4-d44d-4c4e-89f1-94e1d5064948",
   "metadata": {
    "language": "sql",
    "name": "cell12",
    "resultHeight": 112
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    AVG(mape) AS avg_mape, \n",
    "    AVG(smape) AS avg_smape,\n",
    "    AVG(prophet_elapsed_time) AS avg_prophet_time,\n",
    "    AVG(data_preprocessing_time) AS avg_preprocessing_time,\n",
    "    AVG(overall_time) AS avg_overall_time,\n",
    "    SUM(overall_time) AS total_time\n",
    "FROM\n",
    "    prophet_model_performance;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a541b4-7bde-450f-8409-cc6edd573c53",
   "metadata": {
    "collapsed": false,
    "name": "cell14",
    "resultHeight": 302
   },
   "source": [
    "### 6. Generate Boxplot for mape and overall time\n",
    "\n",
    "Packages:\n",
    "1. matplotlib\n",
    "2. snowflake-snowpark-python\n",
    "3. pandas\n",
    "4. scikit-learn\n",
    "5. prophet\n",
    "6. numpy\n",
    "7. seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29bf6eb-ff82-44b4-8e84-1e41b0432375",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell9",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "session = get_active_session()\n",
    "session.use_database(\"ml\")\n",
    "session.use_schema(\"retail_store\")\n",
    "\n",
    "performance = session.table(\"prophet_model_performance\")\n",
    "performance = performance.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86465e8-950c-418c-94f4-19d490cfb764",
   "metadata": {
    "collapsed": false,
    "name": "cell26",
    "resultHeight": 44
   },
   "source": [
    "- Distribution plot for mape values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba88561-4d89-4e6a-9612-f0675e0b2cd9",
   "metadata": {
    "language": "python",
    "name": "cell25",
    "resultHeight": 994
   },
   "outputs": [],
   "source": [
    "sns.displot(performance[\"MAPE\"], kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc03d9bb-b8c8-413f-b4c8-904196a3291e",
   "metadata": {
    "collapsed": false,
    "name": "cell16",
    "resultHeight": 44
   },
   "source": [
    "- Boxplot for mape values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a196d-5738-4ce3-bc06-1431fc5d5469",
   "metadata": {
    "language": "python",
    "name": "cell27",
    "resultHeight": 995
   },
   "outputs": [],
   "source": [
    "sns.displot(performance[\"MAPE\"][performance[\"MAPE\"] < 0.6], kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27772bff-8489-4e8e-a624-cde470cbdada",
   "metadata": {
    "language": "python",
    "name": "cell15",
    "resultHeight": 564
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (3,3))\n",
    "plt.boxplot(performance[\"MAPE\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c7de9a-aa83-4943-8bdc-3e89461b530e",
   "metadata": {
    "collapsed": false,
    "name": "cell17",
    "resultHeight": 44
   },
   "source": [
    "- Boxplot for overall time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e2e3df-4da3-461b-9ad9-3b655eb7a5b0",
   "metadata": {
    "language": "python",
    "name": "cell18",
    "resultHeight": 564
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (3,3))\n",
    "plt.boxplot(performance[\"OVERALL_TIME\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4abee3-e205-4225-8b53-e9601808bf8b",
   "metadata": {
    "collapsed": false,
    "name": "cell21",
    "resultHeight": 46
   },
   "source": [
    "### 7. Isolate highest MAPE outlier\n",
    "\n",
    "Analysis: Store chain that has MAPE outlier are mainly due to the missing/negative sales data which are imputed as 0, which affects the Prophet model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fd8631-8cea-4e1d-99fa-f6c9beeac0f0",
   "metadata": {
    "language": "sql",
    "name": "cell19",
    "resultHeight": 182
   },
   "outputs": [],
   "source": [
    "SELECT * FROM prophet_model_performance\n",
    "WHERE mape < 2 AND mape > 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd26ef29-e6b0-4139-959d-1fc155bc7acb",
   "metadata": {
    "language": "sql",
    "name": "cell22",
    "resultHeight": 112
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE outlier_isolation_prophet_model AS\n",
    "WITH store_preprocessed_transactions AS(\n",
    "    SELECT store_chain_id, purchase_amount, date, offer_date FROM preprocessed_transactions\n",
    "    WHERE store_chain_id=3\n",
    "),\n",
    "prophet_dataset AS(\n",
    "    WITH filtered_transactions AS (\n",
    "        SELECT \n",
    "            store_chain_id,\n",
    "            date,\n",
    "            purchase_amount, \n",
    "            offer_date\n",
    "        FROM store_preprocessed_transactions\n",
    "        WHERE \n",
    "            (SELECT COUNT(offer_date) FROM store_preprocessed_transactions) = 0 OR\n",
    "            date < (SELECT MIN(offer_date) FROM store_preprocessed_transactions)\n",
    "    )\n",
    "    SELECT \n",
    "        store_chain_id,\n",
    "        date,\n",
    "        SUM(purchase_amount) AS total_sales,\n",
    "    FROM filtered_transactions\n",
    "    GROUP BY store_chain_id, date\n",
    "    ORDER BY store_chain_id, date\n",
    "),\n",
    "date_range AS(\n",
    "    SELECT \n",
    "        MIN(date) AS min_date,\n",
    "        MAX(date) AS max_date,\n",
    "    FROM prophet_dataset\n",
    "),\n",
    "\n",
    "-- Create date table\n",
    "date_table AS (\n",
    "    SELECT \n",
    "        min_date AS date,\n",
    "        max_date \n",
    "    FROM date_range\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        DATEADD(day, 1, date),\n",
    "        max_date\n",
    "    FROM date_table\n",
    "    WHERE date_table.date < date_table.max_date\n",
    ")\n",
    "\n",
    "-- Left join with transactions table\n",
    "SELECT \n",
    "    dt.date,\n",
    "    COALESCE(s.total_sales, 0) AS total_sales,\n",
    "FROM date_table dt\n",
    "LEFT JOIN prophet_dataset s\n",
    "    ON dt.date = s.date\n",
    "ORDER BY s.date;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333a9a7d-c3ba-4db3-b661-bed23bd729ed",
   "metadata": {
    "language": "python",
    "name": "cell23",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TEST_SIZE = 14\n",
    "TRAIN_SIZE = TEST_SIZE * 4\n",
    "\n",
    "# Read preprocessed dataset\n",
    "session = get_active_session()\n",
    "session.use_database(\"ml\")\n",
    "session.use_schema(\"retail_store\")\n",
    "\n",
    "transactions_df = session.table(\"outlier_isolation_prophet_model\")\n",
    "transactions_df = transactions_df.to_pandas()\n",
    "transactions_df = transactions_df[[\"DATE\", \"TOTAL_SALES\"]]\n",
    "transactions_df[\"DATE\"] = pd.to_datetime(transactions_df[\"DATE\"])\n",
    "transactions_df = transactions_df.sort_values(by='DATE', ignore_index=True)\n",
    "\n",
    "\n",
    "# Rename columns and split train test set\n",
    "transactions_df = transactions_df.rename(columns={\"DATE\": \"ds\"})\n",
    "transactions_df = transactions_df.rename(columns={\"TOTAL_SALES\": \"y\"})\n",
    "\n",
    "transactions_df[\"y\"] = transactions_df[\"y\"] + 1\n",
    "\n",
    "FLOOR = 0\n",
    "CAP = transactions_df[\"y\"].max()\n",
    "\n",
    "transactions_df[\"floor\"] = 0\n",
    "transactions_df[\"cap\"] = CAP\n",
    "\n",
    "# Split train test set\n",
    "test_set = transactions_df.iloc[-TEST_SIZE:]\n",
    "transactions_df = transactions_df.iloc[:-TEST_SIZE]\n",
    "\n",
    "\n",
    "# Fit model\n",
    "train_data = transactions_df[-TRAIN_SIZE:]\n",
    "\n",
    "model = Prophet(\n",
    "    seasonality_mode=\"multiplicative\",\n",
    "    growth=\"logistic\"\n",
    ")\n",
    "model.fit(train_data)\n",
    "\n",
    "df_future = model.make_future_dataframe(periods=TEST_SIZE, freq=\"D\")\n",
    "df_future[\"floor\"] = FLOOR\n",
    "df_future[\"cap\"] = CAP\n",
    "prophet_predictions = model.predict(df_future)\n",
    "\n",
    "predictions = prophet_predictions[\"yhat\"].iloc[-TEST_SIZE:].values\n",
    "val_data = transactions_df[\"y\"].iloc[-TEST_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84f533-11d9-45dc-9d98-b4a3f75a679a",
   "metadata": {
    "language": "python",
    "name": "cell24",
    "resultHeight": 858
   },
   "outputs": [],
   "source": [
    "def plot_graph(train_values, actual_values, predictions):\n",
    "    x_train = np.linspace(0, len(train_values), len(train_values))\n",
    "    x = np.linspace(len(train_values), len(train_values) + len(actual_values), len(actual_values))\n",
    "\n",
    "    plt.plot(x_train, train_values)\n",
    "    plt.plot(x, actual_values)\n",
    "    plt.plot(x, predictions)\n",
    "    plt.legend([\"Train Data\", \"Actual Sales\", \"Predictions\"])\n",
    "    plt.show()\n",
    "\n",
    "plot_graph(train_data[\"y\"].iloc[-56:], val_data, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19f00e-4bcf-47e4-a69e-4afbf2b715fa",
   "metadata": {
    "language": "python",
    "name": "cell7",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
